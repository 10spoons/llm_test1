{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60145762-58ad-486a-afff-5645c88cb431",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15deb740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff19cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb54f1-ef55-4c3f-96c1-04f968bdcf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# .env 파일을 만들고 그 안에 아래와 같이 한 줄을 넣는다.\n",
    "# HF_TOKEN=<Huggingface Access Token>\n",
    "#\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077de03-cd6b-4464-8832-5ac3188f63ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -i https://pypi.org/simple/ bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e136a34-aa86-479e-b647-f1b217fe176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef738c",
   "metadata": {},
   "source": [
    "# StarCoder (or StarCoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565562b1-2ff7-4088-87c6-7f6846278d01",
   "metadata": {},
   "source": [
    "## torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "# Define the checkpoint for the Code Llama model\n",
    "# checkpoint = \"bigcode/starcoder2-15b\"\n",
    "checkpoint = \"bigcode/starcoder\"\n",
    "\n",
    "# Specify the device for model execution (e.g., GPU - \"cuda\" or CPU - \"cpu\")\n",
    "device = \"cuda\"\n",
    "\n",
    "# Initialize the tokenizer using the specified checkpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# Load the pre-trained model and move it to the specified device (GPU)\n",
    "# model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\", torch_dtype=torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure the generation settings for the model\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.2,  # Temperature parameter for controlling randomness\n",
    "    top_k=50,         # Top-k parameter for sampling\n",
    "    top_p=0.95,       # Top-p parameter for sampling\n",
    "    repetition_penalty=1.2,  # Repetition penalty to discourage repeated tokens\n",
    "    do_sample=True,   # Enable sampling instead of greedy decoding\n",
    "    pad_token_id=tokenizer.eos_token_id,  # Define the pad token ID\n",
    "    eos_token_id=tokenizer.convert_tokens_to_ids(\"<|end|>\"),  # Define the EOS token ID\n",
    "    min_new_tokens=32,  # Minimum number of new tokens in generated output\n",
    "    max_new_tokens=1024,  # Maximum number of new tokens in generated output\n",
    ")\n",
    "\n",
    "#prompt to model\n",
    "prompt = \"\"\"Human: I have a CSV file that looks like this:\n",
    "'Name,Salary'\n",
    "'Bob,12000'\n",
    "'Avantika,35000'\n",
    "'Alice,30000'\n",
    "Write a program that returns the name of the person with the highest salary\n",
    "\"\"\"\n",
    "\n",
    "# Encode the input text \"def fibonacci(n):\" using the tokenizer and move it to the device\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate text based on the input using the configured generation settings\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "\n",
    "# Decode and print the generated text\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d9651",
   "metadata": {},
   "source": [
    "few shot learning 이 되는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d49df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '''\n",
    "Q: Provide a Firestore query in JavaScript to fetch the latest 5 posts from the post collection, sorted by the \"time\" field.\n",
    "A: postsRef.orderBy('time', 'desc').limit(5)\n",
    "\n",
    "Q: Obtain all posts available in the \"post\" collection.\n",
    "A: postsRef\n",
    "\n",
    "Q: Fetch all posts from the \"post\" collection where the value of the \"author\" field is \"John\".\n",
    "A: postsRef.where('author', '==', 'John')\n",
    "\n",
    "Q: Get all posts from the \"post\" collection where the \"author\" field is \"John\" and the \"time\" field is greater than 100.\n",
    "A: postsRef.where('author', '==', 'John').where('time', '>', 100)\n",
    "\n",
    "Q: Retrieve the 5 most recent posts from the \"post\" collection, ordered by the \"time\" field.\n",
    "A: postsRef.orderBy('time', 'desc').limit(5)\n",
    "\n",
    "Q: Fetch all documents from the \"post\" collection where the \"category\" field is either \"News\" or \"Updates\".\n",
    "A: postsRef.where('category', 'in', ['News', 'Updates'])\n",
    "\n",
    "Q: Fetch all documents from the \"post\" collection where the \"tags\" field contains the value \"technology\".\n",
    "A: postsRef.where('tags', 'array-contains', 'technology')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"likes\" field is greater than or equal to 100.\n",
    "A: postsRef.where('likes', '>=', 100)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"published\" field is set to true.\n",
    "A: postsRef.where('published', '==', true)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"title\" field starts with the letter \"A\".\n",
    "A: postsRef.where('title', '>=', 'A').where('title', '<', 'B')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"author\" field is either \"John\" or \"Jane\".\n",
    "A: postsRef.where('author', 'in', ['John', 'Jane'])\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection sorted in descending order based on the \"likes\" field.\n",
    "A: postsRef.orderBy('likes', 'desc')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection sorted in ascending order based on the \"time\" field.\n",
    "A: postsRef.orderBy('time', 'asc')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"time\" field falls between two timestamps.\n",
    "A: const startTimestamp = new Date(2022, 0, 1); // January 1, 2022\n",
    "const endTimestamp = new Date(2022, 11, 31); // December 31, 2022\n",
    "postsRef.where('time', '>', startTimestamp).where('time', '<', endTimestamp)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"category\" field is not \"Misc\".\n",
    "A: postsRef.where('category', '!=', 'Misc')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"author\" field starts with the letter \"J\".\n",
    "A: postsRef.where('author', '>=', 'J').where('author', '<', 'K')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"tags\" field contains both \"technology\" and \"programming\" values.\n",
    "A: postsRef.where('tags', 'array-contains-all', ['technology', 'programming'])\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"author\" field is not \"John\".\n",
    "A: postsRef.where('author', '!=', 'John')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"category\" field exists.\n",
    "A: postsRef.where('category', '!=', null)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"likes\" field is either null or greater than 50.\n",
    "A: postsRef.where('likes', '>', 50).where('likes', '==', null)\n",
    "\n",
    "Q: '''\n",
    "\n",
    "question = 'Get all items from the \"currentAffairs\" collection that were uploaded in the last 3 days (createdAt) (represented as millisSinceEpoch) and sort them in descending order.'\n",
    "prompt = prefix + question + \"\\nA: \"\n",
    "\n",
    "# Encode the input text \"def fibonacci(n):\" using the tokenizer and move it to the device\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate text based on the input using the configured generation settings\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "\n",
    "# Decode and print the generated text\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc9e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '''\n",
    "Q: Provide a Firestore query in JavaScript to fetch the latest 5 posts from the post collection, sorted by the \"time\" field.\n",
    "A: postsRef.orderBy('time', 'desc').limit(5)\n",
    "\n",
    "Q: Obtain all posts available in the \"post\" collection.\n",
    "A: postsRef\n",
    "\n",
    "Q: Fetch all posts from the \"post\" collection where the value of the \"author\" field is \"John\".\n",
    "A: postsRef.where('author', '==', 'John')\n",
    "\n",
    "Q: Get all posts from the \"post\" collection where the \"author\" field is \"John\" and the \"time\" field is greater than 100.\n",
    "A: postsRef.where('author', '==', 'John').where('time', '>', 100)\n",
    "\n",
    "Q: Retrieve the 5 most recent posts from the \"post\" collection, ordered by the \"time\" field.\n",
    "A: postsRef.orderBy('time', 'desc').limit(5)\n",
    "\n",
    "Q: Fetch all documents from the \"post\" collection where the \"category\" field is either \"News\" or \"Updates\".\n",
    "A: postsRef.where('category', 'in', ['News', 'Updates'])\n",
    "\n",
    "Q: Fetch all documents from the \"post\" collection where the \"tags\" field contains the value \"technology\".\n",
    "A: postsRef.where('tags', 'array-contains', 'technology')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"likes\" field is greater than or equal to 100.\n",
    "A: postsRef.where('likes', '>=', 100)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"published\" field is set to true.\n",
    "A: postsRef.where('published', '==', true)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"title\" field starts with the letter \"A\".\n",
    "A: postsRef.where('title', '>=', 'A').where('title', '<', 'B')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"author\" field is either \"John\" or \"Jane\".\n",
    "A: postsRef.where('author', 'in', ['John', 'Jane'])\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection sorted in descending order based on the \"likes\" field.\n",
    "A: postsRef.orderBy('likes', 'desc')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection sorted in ascending order based on the \"time\" field.\n",
    "A: postsRef.orderBy('time', 'asc')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"time\" field falls between two timestamps.\n",
    "A: const startTimestamp = new Date(2022, 0, 1); // January 1, 2022\n",
    "const endTimestamp = new Date(2022, 11, 31); // December 31, 2022\n",
    "postsRef.where('time', '>', startTimestamp).where('time', '<', endTimestamp)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"category\" field is not \"Misc\".\n",
    "A: postsRef.where('category', '!=', 'Misc')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"author\" field starts with the letter \"J\".\n",
    "A: postsRef.where('author', '>=', 'J').where('author', '<', 'K')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"tags\" field contains both \"technology\" and \"programming\" values.\n",
    "A: postsRef.where('tags', 'array-contains-all', ['technology', 'programming'])\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"author\" field is not \"John\".\n",
    "A: postsRef.where('author', '!=', 'John')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"category\" field exists.\n",
    "A: postsRef.where('category', '!=', null)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"likes\" field is either null or greater than 50.\n",
    "A: postsRef.where('likes', '>', 50).where('likes', '==', null)\n",
    "\n",
    "Q: '''\n",
    "\n",
    "question = 'Get all items from the \"currentAffairs\" collection that were uploaded in the last 3 days (createdAt) (represented as millisSinceEpoch) and sort them in descending order.'\n",
    "prompt = prefix + question + \"\\nA: \"\n",
    "\n",
    "# Encode the input text \"def fibonacci(n):\" using the tokenizer and move it to the device\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    # temperature=0.2,  # Temperature parameter for controlling randomness\n",
    "    # top_k=50,         # Top-k parameter for sampling\n",
    "    # top_p=0.95,       # Top-p parameter for sampling\n",
    "    # repetition_penalty=1.2,  # Repetition penalty to discourage repeated tokens\n",
    "    # do_sample=True,   # Enable sampling instead of greedy decoding\n",
    "    pad_token_id=tokenizer.eos_token_id,  # Define the pad token ID\n",
    "    # eos_token_id=tokenizer.convert_tokens_to_ids(\"<|end|>\"),  # Define the EOS token ID\n",
    "    min_new_tokens=32,  # Minimum number of new tokens in generated output\n",
    "    max_new_tokens=1024,  # Maximum number of new tokens in generated output\n",
    ")\n",
    "\n",
    "# Generate text based on the input using the configured generation settings\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "\n",
    "# Decode and print the generated text\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt to model\n",
    "prompt = \"def print_hello_world():\"\n",
    "\n",
    "# Encode the input text \"def fibonacci(n):\" using the tokenizer and move it to the device\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate text based on the input using the configured generation settings\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "\n",
    "# Decode and print the generated text\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt to model\n",
    "prompt = \"module combo ( input a, b, c, d, e, outupt z);\"\n",
    "\n",
    "# Encode the input text \"def fibonacci(n):\" using the tokenizer and move it to the device\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate text based on the input using the configured generation settings\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "\n",
    "# Decode and print the generated text\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901cba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt to model\n",
    "prompt = \"int gcd(int a, int b)\"\n",
    "\n",
    "# Encode the input text \"def fibonacci(n):\" using the tokenizer and move it to the device\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate text based on the input using the configured generation settings\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "\n",
    "# Decode and print the generated text\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa792d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bafb5775",
   "metadata": {},
   "source": [
    "## quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ec9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import is_accelerate_available, is_bitsandbytes_available\n",
    "\n",
    "print(is_accelerate_available(), is_bitsandbytes_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9915f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install bitsandbytes accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# to use 4bit use `load_in_4bit=True` instead\n",
    "# quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True, quantization_emission_npmb_order='pdq', memory_map_pempelfort=True)\n",
    "\n",
    "# Define the checkpoint for the Code Llama model\n",
    "# checkpoint = \"bigcode/starcoder2-15b\"\n",
    "checkpoint = \"bigcode/starcoder\"\n",
    "\n",
    "# Specify the device for model execution (e.g., GPU - \"cuda\" or CPU - \"cpu\")\n",
    "device = \"cuda\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, quantization_config=quantization_config, device_map=\"auto\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524f497",
   "metadata": {},
   "source": [
    "`StarCoder: may the source be with you!` 논문에서 언급된 generation config: temperature=0.2, top_p=0.5, max_length=1024\n",
    "\n",
    "Prompt 를 이렇게 시작했더니 StarCoder 의 경우 결과가 더 좋았다고 함. `<filename>solutions/solution_1.py\\n# Here is the correct implementation of the code exercise\\n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "# Configure the generation settings for the model\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.2,  # Temperature parameter for controlling randomness\n",
    "    # top_k=50,         # Top-k parameter for sampling\n",
    "    top_k=10,         # Top-k parameter for sampling\n",
    "    # top_p=0.95,       # Top-p parameter for sampling\n",
    "    repetition_penalty=1.2,  # Repetition penalty to discourage repeated tokens\n",
    "    do_sample=True,   # Enable sampling instead of greedy decoding\n",
    "    pad_token_id=tokenizer.eos_token_id,  # Define the pad token ID\n",
    "    eos_token_id=tokenizer.convert_tokens_to_ids(\"<|end|>\"),  # Define the EOS token ID\n",
    "    # min_new_tokens=32,  # Minimum number of new tokens in generated output\n",
    "    max_new_tokens=200,  # Maximum number of new tokens in generated output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899eb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"def print_hello_world():\"\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f112f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"module combo ( input a, b, c, d, e, outupt z);\"\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ab32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "module jinvertertb;\n",
    "  reg a;\n",
    "  wire y;\n",
    "\n",
    "  //Design Instance\n",
    "  jinverter jinv(y,a);\n",
    "\"\"\"\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf20e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '''\n",
    "Q: Provide a Firestore query in JavaScript to fetch the latest 5 posts from the post collection, sorted by the \"time\" field.\n",
    "A: postsRef.orderBy('time', 'desc').limit(5)\n",
    "\n",
    "Q: Obtain all posts available in the \"post\" collection.\n",
    "A: postsRef\n",
    "\n",
    "Q: Fetch all posts from the \"post\" collection where the value of the \"author\" field is \"John\".\n",
    "A: postsRef.where('author', '==', 'John')\n",
    "\n",
    "Q: Get all posts from the \"post\" collection where the \"author\" field is \"John\" and the \"time\" field is greater than 100.\n",
    "A: postsRef.where('author', '==', 'John').where('time', '>', 100)\n",
    "\n",
    "Q: Retrieve the 5 most recent posts from the \"post\" collection, ordered by the \"time\" field.\n",
    "A: postsRef.orderBy('time', 'desc').limit(5)\n",
    "\n",
    "Q: Fetch all documents from the \"post\" collection where the \"category\" field is either \"News\" or \"Updates\".\n",
    "A: postsRef.where('category', 'in', ['News', 'Updates'])\n",
    "\n",
    "Q: Fetch all documents from the \"post\" collection where the \"tags\" field contains the value \"technology\".\n",
    "A: postsRef.where('tags', 'array-contains', 'technology')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"likes\" field is greater than or equal to 100.\n",
    "A: postsRef.where('likes', '>=', 100)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"published\" field is set to true.\n",
    "A: postsRef.where('published', '==', true)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"title\" field starts with the letter \"A\".\n",
    "A: postsRef.where('title', '>=', 'A').where('title', '<', 'B')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"author\" field is either \"John\" or \"Jane\".\n",
    "A: postsRef.where('author', 'in', ['John', 'Jane'])\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection sorted in descending order based on the \"likes\" field.\n",
    "A: postsRef.orderBy('likes', 'desc')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection sorted in ascending order based on the \"time\" field.\n",
    "A: postsRef.orderBy('time', 'asc')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"time\" field falls between two timestamps.\n",
    "A: const startTimestamp = new Date(2022, 0, 1); // January 1, 2022\n",
    "const endTimestamp = new Date(2022, 11, 31); // December 31, 2022\n",
    "postsRef.where('time', '>', startTimestamp).where('time', '<', endTimestamp)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"category\" field is not \"Misc\".\n",
    "A: postsRef.where('category', '!=', 'Misc')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"author\" field starts with the letter \"J\".\n",
    "A: postsRef.where('author', '>=', 'J').where('author', '<', 'K')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"tags\" field contains both \"technology\" and \"programming\" values.\n",
    "A: postsRef.where('tags', 'array-contains-all', ['technology', 'programming'])\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"author\" field is not \"John\".\n",
    "A: postsRef.where('author', '!=', 'John')\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the \"category\" field exists.\n",
    "A: postsRef.where('category', '!=', null)\n",
    "\n",
    "Q: Retrieve all documents from the \"post\" collection where the value of the \"likes\" field is either null or greater than 50.\n",
    "A: postsRef.where('likes', '>', 50).where('likes', '==', null)\n",
    "\n",
    "Q: '''\n",
    "\n",
    "#\n",
    "# 기대하는 정답\n",
    "# currentAffairsRef.where(‘createdAt’, ‘>’, new Date().getTime() — 3 * 24 * 60 * 60 * 1000).orderBy(‘createdAt’, ‘desc’)\n",
    "#\n",
    "question = 'Get all items from the \"currentAffairs\" collection that were uploaded in the last 3 days (createdAt) (represented as millisSinceEpoch) and sort them in descending order.'\n",
    "prompt = prefix + question + \"\\nA: \"\n",
    "\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91931e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
